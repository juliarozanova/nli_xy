{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/julia/DATA/Programs/miniconda3/envs/nlp39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification, BertTokenizer\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_handle = 'ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli'\n",
    "# model_handle = 'chromeNLP/textattack_bert_base_MNLI_fixed'\n",
    "# model_handle = 'facebook/bart-large-mnli'\n",
    "# model_name = 'bert-base-uncased-snli-help'\n",
    "# model_handle = '../models/bert-base-uncased-snli-help/'\n",
    "\n",
    "dataset_name = 'multi_nli'\n",
    "split = 'validation_matched'\n",
    "# split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hf_hub_download(repo_id=model_handle, filename=\"config.json\", cache_dir=\"../models/ynie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entailment': 0, 'neutral': 1, 'contradiction': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_handle, resume_download=True)\n",
    "label2id = model.config.label2id\n",
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'bert-base-uncased-snli': {\n",
    "        'entailment': 1,\n",
    "        'neutral': 2, \n",
    "        'contradiction': 0\n",
    "    },\n",
    "\n",
    "    'bert-base-uncased-snli-help': {\n",
    "        'entailment': 1,\n",
    "        'neutral': 2, \n",
    "        'contradiction': 2\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset multi_nli (/home/julia/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n",
      "Loading cached processed dataset at /home/julia/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39/cache-ef0def8b9709d121.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'promptID': Value(dtype='int32', id=None),\n",
       " 'pairID': Value(dtype='string', id=None),\n",
       " 'premise': Value(dtype='string', id=None),\n",
       " 'premise_binary_parse': Value(dtype='string', id=None),\n",
       " 'premise_parse': Value(dtype='string', id=None),\n",
       " 'hypothesis': Value(dtype='string', id=None),\n",
       " 'hypothesis_binary_parse': Value(dtype='string', id=None),\n",
       " 'hypothesis_parse': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = load_dataset_builder(dataset_name)\n",
    "dataset = load_dataset(dataset_name, split=split).filter(lambda x :  x['label']!=-1)\n",
    "builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m\n\u001b[1;32m     23\u001b[0m guess_label2id \u001b[39m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mentailment\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \n\u001b[1;32m     26\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcontradiction\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     29\u001b[0m \u001b[39m# best for bert-base-uncased-snli\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# guess_label2id = {\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#     'entailment': 1,\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m#     'neutral': 2, \u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m#     'contradiction': 0\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39malign_labels_with_mapping(label2id[model_name], \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[39m# dataset = dataset.align_labels_with_mapping(label2id, 'label')\u001b[39;00m\n\u001b[1;32m     38\u001b[0m dataset\u001b[39m.\u001b[39mset_format(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "# \n",
    "# guess_label2id = {\n",
    "#     'entailment': 0,\n",
    "#     'neutral': 2, \n",
    "#     'contradiction': 1\n",
    "# }\n",
    "\n",
    "# mnli same as dataset label2id\n",
    "# guess_label2id = {\n",
    "#     'entailment': 0,\n",
    "#     'neutral': 1, \n",
    "#     'contradiction': 2\n",
    "# }\n",
    "\n",
    "# best for roberta-large-mnli\n",
    "# guess_label2id = {\n",
    "#     'entailment': 2,\n",
    "#     'neutral': 1, \n",
    "#     'contradiction': 0\n",
    "# }\n",
    "\n",
    "#guess for for bert-base-uncased-snli-help\n",
    "guess_label2id = {\n",
    "    'entailment': 1,\n",
    "    'neutral': 2, \n",
    "    'contradiction': 2\n",
    "}\n",
    "\n",
    "# best for bert-base-uncased-snli\n",
    "# guess_label2id = {\n",
    "#     'entailment': 1,\n",
    "#     'neutral': 2, \n",
    "#     'contradiction': 0\n",
    "# }\n",
    "\n",
    "dataset = dataset.align_labels_with_mapping(label2id[model_name], 'label')\n",
    "# dataset = dataset.align_labels_with_mapping(label2id, 'label')\n",
    "dataset.set_format(type=\"torch\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "9810    2\n",
       "9811    2\n",
       "9812    1\n",
       "9813    1\n",
       "9814    2\n",
       "Name: y_true, Length: 9815, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results = pd.DataFrame(results)\n",
    "results[\"y_true\"] = dataset['label'].to('cpu')\n",
    "results[\"y_true\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_handle)\n",
    "except OSError:\n",
    "    tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-snli')\n",
    "max_length=256\n",
    "def encode(examples):\n",
    "    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/julia/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39/cache-72fe16795de83174.arrow\n",
      "Loading cached processed dataset at /home/julia/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39/cache-ea1d2b65e13ac866.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(encode, batched=True)\n",
    "dataset = dataset.map(lambda examples: {\"labels\": examples[\"label\"]}, batched=True)\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"premise\", \"hypothesis\",  \"labels\"], device='cuda')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The new rights are nice enough</td>\n",
       "      <td>Everyone really likes the newest benefits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This site includes a list of all award winners...</td>\n",
       "      <td>The Government Executive articles housed on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>uh i don't know i i have mixed emotions about ...</td>\n",
       "      <td>I like him for the most part, but would still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>yeah i i think my favorite restaurant is alway...</td>\n",
       "      <td>My favorite restaurants are always at least a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>i don't know um do you do a lot of camping</td>\n",
       "      <td>I know exactly.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true                                            premise  \\\n",
       "0       2                     The new rights are nice enough   \n",
       "1       2  This site includes a list of all award winners...   \n",
       "2       1  uh i don't know i i have mixed emotions about ...   \n",
       "3       2  yeah i i think my favorite restaurant is alway...   \n",
       "4       2         i don't know um do you do a lot of camping   \n",
       "\n",
       "                                          hypothesis  \n",
       "0         Everyone really likes the newest benefits   \n",
       "1  The Government Executive articles housed on th...  \n",
       "2  I like him for the most part, but would still ...  \n",
       "3  My favorite restaurants are always at least a ...  \n",
       "4                                    I know exactly.  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset\n",
    "df = df[:]\n",
    "results['premise'] = df['premise']\n",
    "results['hypothesis'] = df['hypothesis']\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:39<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    for inputs in tqdm(dataloader):\n",
    "        batch_outputs = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "        batch_logits = batch_outputs['logits'].to('cpu')\n",
    "        batch_predictions = np.argmax(batch_logits, axis=1)\n",
    "        y_pred += batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"y_pred\"] = y_pred\n",
    "results[\"y_pred\"] = results[\"y_pred\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.loc[results.y_true!=results.y_pred].value_counts()\n",
    "# results.loc[results.y_true==results.y_pred].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred\n",
    "#2112\n",
    "#y_true\n",
    "#1021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_score(results[\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m], results[\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[39m# f1_score(results[\"y_true\"], results[\"y_pred\"], average=\"macro\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(results[\"y_true\"], results[\"y_pred\"])\n",
    "# f1_score(results[\"y_true\"], results[\"y_pred\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360163015792155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(results['y_pred'], results['y_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: y_pred, dtype: int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"y_pred\"].loc[results.y_true==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2380\n",
       "2     965\n",
       "0     134\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"y_pred\"].loc[results.y_true==1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2881\n",
       "1    2627\n",
       "0     828\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"y_pred\"].loc[results.y_true==2].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| model | accuracy on snli| accuracy on mnli validation_matched|\n",
    "| --- | --- | --- |\n",
    "|ynie | 91.8464| --- |\n",
    "| bert-base-uncased-snli-help | 73.381 | 61.82 |\n",
    "| chromeNLP | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5631747dc3ad6eb60a3da5f4cdcebe149d51d3449295229bf66075ef01b5a217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
